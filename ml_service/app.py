from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.responses import FileResponse
from pathlib import Path
import pandas as pd
from bin_packing import pack_cluster
from train import train_and_cluster, OUTPUTS

app = FastAPI(title="Farmer ML Service")
DATA = Path("data")
DATA.mkdir(exist_ok=True)


@app.get("/status")
def status():
    return {"ok": True, "message": "ML service running fine"}


@app.post("/upload")
async def upload_csv(file: UploadFile = File(...)):
    """
    Upload a CSV file containing:
    farmer_id, village, latitude, longitude, load_kg
    """
    if not file.filename.endswith(".csv"):
        raise HTTPException(400, "Upload a CSV file.")

    path = DATA / "farmers.csv"
    path.write_bytes(await file.read())
    df = pd.read_csv(path)

    # âœ… Validate required columns
    required_cols = {"farmer_id", "village", "latitude", "longitude", "load_kg"}
    missing = required_cols - set(df.columns)
    if missing:
        raise HTTPException(400, f"Missing columns in CSV: {missing}")

    return {"saved_as": str(path), "rows": len(df)}


@app.post("/train")
def train(k: int = Form(5)):
    """
    Train a K-Means model on latitude, longitude, and load_kg.
    """
    csv_path = DATA / "farmers.csv"
    if not csv_path.exists():
        raise HTTPException(404, "Upload CSV first at /upload.")

    df_out, out_csv = train_and_cluster(str(csv_path), k=k)
    return {"rows": len(df_out), "clustered_csv": out_csv}


@app.post("/assign")
def assign(capacity: int = Form(5000)):
    """
    Assign trucks within each cluster using bin packing.
    """
    clustered = OUTPUTS / "clustered.csv"
    if not clustered.exists():
        raise HTTPException(404, "Run /train first.")

    df = pd.read_csv(clustered)

    if "cluster" not in df.columns:
        raise HTTPException(400, "Cluster column missing in clustered.csv")

    # âœ… Group by cluster and perform truck assignment
    assignments = []
    for cluster_id, group in df.groupby("cluster"):
        farmers = group[["farmer_id", "load_kg"]].to_dict(orient="records")
        trucks = pack_cluster(farmers, capacity)
        for t_idx, truck in enumerate(trucks, start=1):
            for fid in truck:
                assignments.append({
                    "farmer_id": fid,
                    "cluster": int(cluster_id),
                    "assigned_truck": f"cluster{cluster_id}_truck{t_idx}"
                })

    # âœ… Merge truck assignments with clustered data
    assign_df = pd.DataFrame(assignments)

    # ðŸ‘‰ Keep cluster column intact and merge cleanly
    if "cluster" in assign_df.columns and "cluster" in df.columns:
        out = pd.merge(df, assign_df, on=["farmer_id", "cluster"], how="left")
    else:
        out = pd.merge(df, assign_df, on="farmer_id", how="left")

    # âœ… Standardize header case
    out.columns = [c.strip().lower() for c in out.columns]

    # âœ… Save output file
    out_path = OUTPUTS / "assignments.csv"
    out.to_csv(out_path, index=False)

    return {
        "assignments_csv": str(out_path),
        "rows": len(out),
        "headers": list(out.columns),
    }


@app.get("/download/clustered")
def download_clustered():
    """
    Download the clustered CSV generated by /train.
    """
    p = OUTPUTS / "clustered.csv"
    if not p.exists():
        raise HTTPException(404, "Train first.")
    return FileResponse(p, filename="clustered.csv")


@app.get("/download/assignments")
def download_assignments():
    """
    Download the truck assignment CSV generated by /assign.
    """
    p = OUTPUTS / "assignments.csv"
    if not p.exists():
        raise HTTPException(404, "Assign first.")
    return FileResponse(p, filename="assignments.csv")
